---
title: "Exploratory Analyses for Missing Data in Meta-Analyses: A Tutorial"
csl: ../addons/alcohol-and-alcoholism.csl
output:
  bookdown::pdf_document2: 
    fig_caption: yes
    includes:
      in_header: ../addons/style.sty
    toc: false
    number_sections: no
  bookdown::word_document2: 
    reference_docx: ../addons/styles_word.docx
bibliography: ../addons/references.json
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)#, fig.pos = "p", out.extra = "")
```


```{r, message=FALSE, echo=FALSE, warning = FALSE}
library(naniar)
library(ggplot2)
library(visdat)
library(tidyverse)
library(tidyselect)
library(gridExtra)
library(grid)
library(cowplot)
library(viridisLite)
library(tidyr)
adt_data <- readRDS("../../data/adt_data.RDS") 

source("../../code/wrappers.R")
# myvars <- names(adt_data) %in% c("pk_es", "studyid", "_referencesummary","authoryear","varid", "state",
#                                  "dvsucat", "dvmicro", "estimingpost", "esctobnpost","estxobnpost" )
data_named <- adt_data %>%
  select(
         # `Study ID` = studyid, 
         `Effect Size` = es_g, 
         `Standard Error` = se_g,
         `Timing of Follow-Up` = estimingpost,
         `Design` = design,
         # `State` = state,
         `Group 1 Treatment Category` = g1txcat, 
         `Group 1 Treatment Location` = g1loc, 
         `Group 1 Hrs Per Week` = g1hrsperweek,
         `Group 1 Treatment Days` = g1txdays, 
         `Group 1 No. Session` = g1numsessions,
         `Group 1 Mean Age` = g1age,
         `Group 1 Pct White` = g1perwhite, 
         `Group 1 Pct Black` = g1perblack,
         `Group 1 Pct Hispanic` = g1perhisp,
         `Group 1 Pct Male` = g1permale,
         `Group 2 Treatment Category` = g2txcat, 
         `Group 2 Treatment Location` = g2loc, 
         `Group 2 Hrs Per Week` = g2hrsperweek,
         `Group 2 Treatment Days` = g2txdays, 
         `Group 2 No. Session` = g2numsessions,
         `Group 2 Mean Age` = g2age,
         `Group 2 Pct White` = g2perwhite, 
         `Group 2 Pct Black` = g2perblack,
         `Group 2 Pct Hispanic` = g2perhisp,
         `Group 2 Pct Male` = g2permale)#adt_data[!myvars]

data <- adt_data %>%
   select(
      # studyid,
      es_g,
      se_g,
      estimingpost,
      design, 
      # state,
      g1txcat,
      g1loc,
      g1hrsperweek,
      g1txdays,
      g1numsessions,
      g1age,
      g1perwhite,
      g1perblack,
      g1perhisp,
      g1permale,
      g2txcat,
      g2loc,
      g2hrsperweek,
      g2txdays,
      g2numsessions,
      g2age,
      g2perwhite,
      g2perblack,
      g2perhisp,
      g2permale)

key <- read_csv("../../code/keys_names.csv")
raw_to_named <- function(x){
  out = key %>% filter(raw == x) %>%
    pull(named)
  return(out)
}

any_na_tab <- tibble(
  se = data$se_g,
  any_na = apply(data, 1, FUN=function(x) as.integer(sum(is.na(x)) > 0))
) %>%
  mutate(se_na = any_na * se)
```

# Introduction


Systematic reviews of substance abuse research hold great promise for better understanding effects of interventions [@newbury-birchSystematicReviewEfficacy2018; @ramseyTechnologybasedAlcoholInterventions2019; @tanner-smithAdolescentSubstanceUse2016; @tanner-smithComparativeEffectivenessOutpatient2013; @whiteOnlineAlcoholInterventions2010; @yuvarajEffectivenessWorkplaceIntervention2019]. 
Traditional meta-analyses summarize the results of ensembles of studies of interventions, typically reporting the average impact or variation across impacts.
Alternatively, meta-regression, which is analogous to standard linear regression, examines how the effectiveness of interventions is related to the type of treatment (e.g., type of therapy provided), how or on whom it was implemented, or the context in which it was studied [see @cooperHandbookResearchSynthesis2019].
However, meta-analyses frequently contend with missing data [@pigottHandlingMissingData2019].
A vast literature on missing data methodology highlights the ways missingness can bias statistical inferences, examines conditions under which these biases can be corrected, and proposes various statistical procedures to do so [@grahamMissingDataAnalysis2009; @littleStatisticalAnalysisMissing2002; @pigottHandlingMissingData2019; @pigottMissingPredictorsModels2001; @rubinInferenceMissingData1976; @schaferMissingDataOur2002; @vanbuurenFlexibleImputationMissing2018].



<!-- Methodological tools such as meta-regression can formally test relationships between an intervention's impact and how or on whom it is studied [@cooperHandbookResearchSynthesis2019; @hedgesStatisticalMethodsMetaanalysis1985; @tiptonHistoryMetaregressionTechnical2019]. -->
<!-- However, such tools must contend with the real-world difficulties of modern research syntheses, including the fact that it is often impossible to extract all relevant information from the literature to conduct such analyses. -->

<!-- The fact that not every study reports the information required to run a meta-regression means that many meta-analyses face missing data problems [@pigottHandlingMissingData2019]. -->
<!-- Issues with missing data are not new.  -->
<!-- There is a vast literature on methods for handling missing data in primary studies, as well as work on related issues in meta-analysis [@grahamMissingDataAnalysis2009; @littleStatisticalAnalysisMissing2002; @pigottHandlingMissingData2019; @pigottMissingPredictorsModels2001; @rubinInferenceMissingData1976; @schaferMissingDataOur2002; @vanbuurenFlexibleImputationMissing2018]. -->
<!-- This literature highlights the ways that missingness can bias an analysis, examines conditions under which these biases can be corrected, and proposes various statistical procedures to adjust for bias or accurately compute uncertainty. -->

A key assumption of many analysis methods for incomplete data (i.e., data with missing values) is that analysts understand what data is missing and the mechanism that drives missingness.
Much of the literature on missing data has focused on the implications of this assumption [@littleStatisticalAnalysisMissing2002; @pigottHandlingMissingData2019]. 
Yet, outside of some statistical tests [e.g., @littleTestMissingCompletely1988], there is little guidance for forming and examining theories about missingness [@tierneyExpandingTidyData2018].
Various researchers have suggested analysts can better understand missingness in their data through exploratory analyses, including visual and numerical summaries [@bujaInteractiveHighdimensionalData1996; @chengVisuallyExploringMissing2015] akin to classical exploratory data analyses [@tukeyFutureDataAnalysis1962].
These explorations, which occur before running confirmatory statistical analyses, can shed greater light on key issues relevant to missingness.
Tools for doing so are only now emerging in statistics, but these tools have yet to gain broader traction in quantitative disciplines [@tierneyExpandingTidyData2018; @tierneyVisdatVisualisingWhole2017]. 
Nor has this approach garnered much discussion among meta-analysts, where missing data is a common problem. 

Because a meta-analysis involves an ensemble of effects (i.e., intervention impacts) reported by primary studies, there are at least three different types of missing data in a meta-analysis, each of which would require its own exploratory analysis.
First, data could be missing on individual participants within studies, including their outcomes in the study or other characteristics (e.g., their age, race, prior substance use) [e.g., @higginsImputationMethodsMissing2008].
Second, entire studies or effects may be missing from a meta-analytic dataset if they are not reported or published, including for reasons related publication selection and bias [@rosenthalFileDrawerProblem1979; @hedgesEstimationEffectSize1984; @rothsteinPublicationBiasMetaanalysis2005]. 
Third, and the focus of this article, missingness may refer to information that could not be extracted from a completed study by a meta-analyst [@pigottMissingPredictorsModels2001]. 
This may occur if a study fails to report enough detail for analysts to back out effect estimates, standard errors, or study- and effect-level characteristics.

This tutorial examines exploratory analysis methods for studying missingness that arises from incomplete reporting as described above.
The focus of the tutorial involves a dataset on substance abuse interventions typical of those used in meta-regression, a statistical model analogous to standard linear regression.
The following section describes a meta-analytic dataset on substance abuse interventions that will be used to demonstrate key concepts in EMA.
We then demonstrate an EMA on that dataset, including a series of numerical and visual summaries aimed at better understanding missingness and its implications for analysis. 

<!-- The following section clarifies the types of missing data for which these methods are appropriate. -->
<!-- We then describe principles of missing data that can guide exploratory analyses.  -->
<!-- Finally, we demonstrate an exploration of missing data on a meta-analysis of substance abuse interventions for adolescents. -->
<!-- Additional examples and executable code are available as part of the supplementary material for this article. -->



<!-- # Missing Data in a Meta-Analysis -->

<!-- Because a meta-analysis involves an ensemble of *effects* (i.e., intervention impacts) reported by primary studies, *missing data* or *missingness* in meta-analysis could refer to at least three different scenarios. -->
<!-- For instance, data could be missing on individual participants within studies, including their outcomes in the study or other characteristics (e.g., their age, race, prior substance use) [e.g., @higginsImputationMethodsMissing2008]. -->
<!-- Missingness could also refer to information that could not be extracted from a completed study by a meta-analyst [@pigottMissingPredictorsModels2001].  -->
<!-- This may occur if a study fails to report enough detail for analysts to back out effect estimates, standard errors, or study- and effect-level characteristics. -->
<!-- Finally, entire studies or effects may be missing from a meta-analytic dataset.  -->
<!-- This might occur if effects (or entire studies) are not reported or published [@rosenthalFileDrawerProblem1979].  -->
<!-- There is empirical evidence that statistically significant results are more likely to be published and hence wind up in a meta-analysis, which can induce *publication bias*, a well-known problem in the field [@hedgesEstimationEffectSize1984; @rothsteinPublicationBiasMetaanalysis2005]. -->
<!-- The studies or effects that are not reported, and thus are not included in a meta-analysis, can be seen as missing data. -->

<!-- Precisely how to examine, diagnose, and adjust for missing data will be different depending on what scenario we mean when we say "missing data." -->
<!-- For instance, meta-analysts have used *funnel plots* to assess whether their systematic review is missing studies or effects due to publication bias [@eggerBiasMetaanalysisDetected1997; @lightSummingScienceReviewing1984]. -->
<!-- Our focus will be on the second scenario, where information cannot be extracted from some studies.  -->
<!-- This is a common problem in meta-analysis that can limit the accuracy of any statistical inferences [@pigottHandlingMissingData2019; @tiptonCurrentPracticesMetaregression2019]. -->


# Data

A prime example of an incomplete data meta-analysis can be seen in data from @tanner-smithAdolescentSubstanceUse2016, who examined the impacts of substance abuse interventions for adolescents on subsequent substance use. 
Tanner-Smith et al. extracted effects from 61 randomized trials and quasi-experiments, and include $k = 95$ different effect size estimates.
These data will be used to illustrate useful tools to exploring missingness in this tutorial.

Tanner-Smith et al. identified a range of intervention types that have been studied in different venues and on different types of adolescent substance users.
They found interventions that focus on cognitive behavioral therapy (CBT), family therapy, and pharmacological therapy. 
Individuals in studies present using marijuana, alcohol, and/or opioids, and have different racial and socioeconomic backgrounds. 
Each effect involves the difference between two groups of study participants (referred to here as *Group 1* and *Group 2*). 
Some reported effects contrasted a given intervention with a placebo or with a "usual care" condition where individuals received services but no explicit drug treatment (e.g., youth in residential care who receive standard residential services but not drug treatment).
Others contrasted two alternative interventions or implementations.
Tanner-Smith et al. documented the intensity (in hours per week), duration (in days), and location (in- our out-patient) of treatment for each group.
Finally, Tanner-Smith et al. recorded effect estimates at different time points after intake.
In all, their raw data totaled some $k = 328$ effect estimates and $p = 43$ variables for each effect.

<!-- In addition to estimated effects and their standard errors, Tanner-Smith et al. documented the types of interventions being contrasted, as well as their intensity and context. -->
<!-- This included where interventions occurred, and how much time subjects spent in the intervention.  -->
<!-- For instance, if a study contrasted two interventions, Tanner-Smith et al. documented how many hours per week subjects in each group spent in receiving treatment. -->
<!-- They also documented the demographics of subjects in the studies, such as the percentage of subjects who were minorities, as well as the substances that subjects reported using. -->

Tanner-Smith et al. fit meta-regression models to their data in order to examine how treatment impacts varied according to the type of therapies and individuals studied. 
Meta-regression is a statistical model analogous to linear regression, wherein effect estimates are regressed on covariates pertaining to those effects, including study- and effect-level information [@hedgesFittingContinuousModels24; @hedgesFittingCategoricalModels22; @cooperHandbookResearchSynthesis2019].
They found that assertive continuing care (ACC), behavioral therapy, (CBT), motivational enhancement therapy (MET), and family therapy tended to be more effective than generic "practice as usual" interventions that often involved referrals to community services.
However, they did not find strong relationships between the characteristics of adolescents in the studies and the effectiveness of interventions after controlling for intervention type.

A complicating factor in conducting these analyses was that some of the data were missing. 
For instance, not all studies reported treatment intensity (in hours per week) or the racial makeup of each group in the study.
To address these issue, Tanner-Smith et al. opted to estimate their meta-regression models using the expectation-maximization (EM) algorithm, which has been an important tool for analyzing incomplete data  [@dempsterMaximumLikelihoodIncomplete1977; @grahamMethodsHandlingMissing2003].
The EM algorithm has also been studied as a useful approach to estimation when missing covariates in a statistical model, which was primarily the issue facing Tanner-Smith et al. [@ibrahimIncompleteDataGeneralized1990; @ibrahimMissingCovariatesGeneralized1999].

There are several alternatives to the EM algorithm. 
@pigottHandlingMissingData2019 discusses methods applicable to meta-analyses such as multiple imputation and full information maximum likelihood (FIML), as well as complete- and available-case analysis methods.
Each of these methods, including EM, rely on assumptions about the reason data are missing, and their effectiveness can be limited by how much data are missing [@grahamMissingDataAnalysis2009; @littleStatisticalAnalysisMissing2002; @pigottReviewMethodsMissing2001; @rubinMultipleImputationNonresponse1987; @rubinInferenceMissingData1976; @schaferMissingDataOur2002; @vanbuurenFlexibleImputationMissing2018]. 




# Exploratory Missingness Analyses

<!-- [NOTE TO JAKE: TIDY UP THE NOTATION.  -->
<!-- MAKE THE KEY THRUST: WE NEED TO KNOW ABOUT THE AMOUNT OF MISSING DATA, PATTERNS OF MISSINGNES, AND MECHANISMS. PERHAPS SIMPLIFY DISCUSSION OF EACH.  -->
<!-- ALTERNATIVELY, WE INTRODUCE NOTATION AND THE BIG 3 (AMOUNT, PATTERNS, MECHANISM) -->
<!-- THEN, WE SHOW HOW TO DO THESE IN AN EDA -->
<!-- CONSIDERATION: Looking at individual variables vs. collections of variables] -->

The tools discussed in the remainder of this article facilitate exploratory missingness analyses (EMA) to quantify and visualize missingness in a meta-analytic dataset [@bujaInteractiveHighdimensionalData1996; @chengVisuallyExploringMissing2015; @tierneyExpandingTidyData2018].
The point of conducting an EMA is to better understand the pattern and potential impact of the missing data in a meta-analysis, which can aid researchers to make appropriate choices about an analysis strategy. Researchers can explore whether assumptions about the missingness mechanism are defensible and can also highlight areas where evidence is sparse. 
For example, meta-analysts may hypothesize that average age of the study sample may relate to the effectiveness of an intervention but find that studies report average age in various ways. 
Looking closely at the data collected in a meta-analysis affords opportunities to create moderators based on information reported more frequently across studies [@pigottMethodologicalGuidancePaper2020]. 
EMAs can also highlight gaps in the evidence base by showing what information (e.g., on treatment frequency or setting) is missing from a systematic review.

While the following sections present an example of an EMA, it is worth noting two aspects about EMA to better contextualize this process.
First, it will often be difficult to draw very strong conclusions about missingness mechanisms based on exploratory analyses.
Even proposed tests for missingness mechanisms must be interpreted with caution [@molenberghsEveryMissingnessNot2008; @rhoadsProblemsTestsMissingness2012; @seamanWhatMeantMissing2013].
Instead, EMA can provide support for or help generate theories that explain missingness in ways that are consistent with the assumptions required of incomplete data analysis methods. 
Some of these theories may require consultation with data curators and other individuals who extracted information from the studies reviewed.

Second, there is no single visualization or set of metrics guaranteed to provide a complete picture of missingness for all datasets. 
A plot that is tremendously useful for one dataset may be of less interest for others. 
Any EMA must rely on knowledge of how data were collected and extracted, and can help leverage that knowledge to examine theories about missingness.
Because this process is about exploration, rather than confirmation, it will be subject to the analysts judgment.

In the following sections, we present and discuss an example EMA of Tanner-Smith's et al. data on substance abuse interventions for adolescents.
To simplify presentation, we focus on $p = 20$ variables relevant to the analyses conducted by Tanner-Smith et al.
This example serves to highlight some potential techniques, but it is not exhaustive, and so as part of the supplementary material to this tutorial, we have included a vignette that presents and describes alternative visualizations and numerical summaries of missingness.
Further, though the focus of these data and the resulting EMA pertain to meta-regression, the same general approaches can be used for other meta-analytic data.
Both the demonstration presented in this article and the supplementary vignette are implemented in the `R` software language and draw heavily on the `visdat` and `naniar` libraries with some custom extensions developed specifically for meta-analysis [@tierneyExpandingTidyData2018; @tierneyVisdatVisualisingWhole2017].
Executable code is included with the supplementary materials.


### Notation

Assume a literature search reveals $k$ effect estimates and data is collected on $p$ variables regarding each effect (including the estimate itself).
This can be summarized and stored in a $k \times p$ table where rows correspond to effect estimates and columns correspond to variables concerning those estimates. 
One column would contain the effect estimates themselves, and another would contain the standard error or estimation error variance of those estimates.
The remaining $p-2$ columns could contain effect- or study-level covariates, including summary demographics (e.g., the percent of a study's sample that were minorities), treatment type (e.g., behavioral therapy versus pharmacological interventions), or dosage/duration of an intervention.
These tables are used by most standard meta-analysis software, including Comprehensive Meta-Analysis, the `metafor` library, or OpenMetaAnalyst [@borensteinComprehensiveMetaAnalysisVersion2012; @trikalinosOpenMetaAnalystPowerfulOpensource2012; @viechtbauerConductingMetaanalysesMetafor2010].


The structure of such tables is shown in the matrix $\mathbf{D}$ below. 
In the matrix, $T_i$ denote the effect size estimates and $\sigma_i$ are their standard errors. 
The $X_{ij}$ refer to additional variables collected that pertain to a given effect size and that might be used in an analysis.
Note that $X_{ij}$ may be effect- or study-level covariates.
In a meta-regression, the effect estimates $T_i$ are regressed on the covariates $X_{ij}$ using a weighted least-squares approach [see @cooperHandbookResearchSynthesis2019].

\[
\mathbf{D} =
\left[
\begin{array}{ccccc}
T_1 & \sigma_1 & X_{11} & ... & X_{1,p-2} \\
T_2 & \sigma_2 & X_{21} & ... & \textbf{NA} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
T_k & \sigma_k & \textbf{NA} & ... & X_{k,p-2} \\
\end{array}
\right]
\qquad\qquad
\mathbf{R} =
\left[
\begin{array}{ccccc}
1 & 1 & 1 & ... & 1 \\
1 & 1 & 1 & ... & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots\\
1 & 1 & 0 & ... & 1 \\
\end{array}
\right]
\]


*Missing data* in this context would refer to individual cells in the table that are missing values, and are denoted in $\mathbf{D}$ as **NA**. 
To gain insight about missingness, we can augment the traditional dataset $\mathbf{D}$ with a matrix $\mathbf{R}$, which is comprised of response indicators $R_{ij}$.
These indicators take a value of $R_{ij} = 1$ if entry $i, j$ in the dataset $\mathbf{D}$ is observed, and $R_{ij} = 0$ if it is missing.
For instance, $R_{21} = 1$ because the first element of row 2 ($T_2$) is observed, but $R_{2p} = 0$ because the last element of row 2 is missing (**NA**).

Note that there are both *observed* and *unobserved* data.
The observed data comprises all of the entries in $\mathbf{D}$ for which $R_{ij} = 1$, and we denote it as $\mathbf{D}_{obs}$.
For instance, the observed data would include the effect estimates $T_i$ and standard errors $\sigma_i$.
The unobserved data comprises all of the entries of $\mathbf{D}$ for which $R_{ij} = 0$, including $X_{2, p-2}$ and $X_{k, 1}$.
Denote the unobserved data as $\mathbf{D}_{mis}$.

EMA differ from traditional exploratory data analyses (EDA) because they focus on missingness indicators in $\mathbf{R}$, as well as the relationship between those indicators and the observed data $\mathbf{D}_{obs}$.
Many software tools, including most graphics software used to conduct a standard EDA omit observations with missing values, which would eliminate information about missingness [@tierneyVisdatVisualisingWhole2017].



# Numerical Summaries of Missingness

```{r, echo = F, message = F, warning = F}
any_sum = any_na_tab %>% 
  summarize(raw_pct = mean(any_na) * 100, 
            wt_pct = sum(any_na/se^2)/sum(1/se^2) * 100)
```

One issue with missingness involves how much data is missing, which can affect the accuracy of incomplete data analysis methods like the EM algorithm, multiple imputation, or even complete-case analyses.
@schaferMultipleImputationPrimer1999 suggests that if less than 5% of the data are missing, this can be inconsequential, and @bennettHowCanDeal2001 argues that a missingness rate of over 10% can induce non-negligible bias in statistical analyses.
Statistical guidance regarding the effectiveness of procedures such as multiple imputation or FIML typically typically suggest that they are appropriate when missingness is less than 40% [@jakobsenWhenHowShould2017; @dongPrincipledMissingData2013]. 
However, multiple imputation that involves informative auxiliary variables to impute missing data can perform well at higher rates of missingness under certain assumptions [@madley-dowdProportionMissingData2019].

Missingness rates could refer to several different quantities in the datasets described in the previous section.
First, we could be interested in the total fraction of cells with missing values:
\begin{equation}
\sum_{i=1}^k \sum_{j = 1}^p \frac{1 - R_{ij}}{kp}
\end{equation}
In the subset of the Tanner-Smith et al., data this value is 11.6%.

Second, we can compute the proportion of effects missing any variables:
\begin{equation}
\sum_{i=1}^k \frac{1 - \prod_{j = 1}^p R_{ij}}{k}
\end{equation}
In the data, `r round(any_sum %>% pull(raw_pct), 1)`% of rows are missing at least one value, 
Thus, a complete-case analysis of all variables would retain only about `r floor(100 - any_sum %>% pull(raw_pct))`% of the rows in the data. 

Third, we may wish to know the percentage of effects are missing a given variable (i.e., how much of each column is missing):
\begin{equation}
\sum_{i=1}^k \frac{1 - R_{ij}}{k}
\end{equation}
As an example, just over 24% of the rows in the data are missing the intensity of Group 1's treatment (in hours per week). 
Missingness rates of additional variables are displayed in Table \@ref(tab:pcts).

An alternative to quantifying missingness in terms of raw percentages is to use weighted percentages.
In a meta-analysis, parameters are often estimated by weighting effect size estimates in such a way that the most precisely estimated effects (i.e., that have the smallest standard errors) receive the most weight [@borensteinIntroductionMetaanalysis2009; @cooperHandbookResearchSynthesis2019].
The precision with which we estimate important quantities in a meta-analysis, including meta-regression coefficients, will therefore depend on the precision of the studies included in an analysis.
That is, we will have better estimates of a meta-regression model if the precision of each effect $1/\sigma_i^2$ is large [@hedgesStatisticalMethodsMetaanalysis1985].
Missing a variable for an effect estimate with a large standard error (and thus low precision) can potentially be less detrimental than missing the same variable for an effect estimate with a small standard error.

Thus, when standard errors of effect sizes are fully observed, an alternative way to quantify the extent of missingness is with a precision-weighted percentage.
The weighted percentage
\begin{equation}
\sum_{i=1}^k \frac{\left(1 - \prod_{j = 1}^p R_{ij}\right)/\sigma_i^2}{\sum_{i=1}^k 1/\sigma_i^2}
\end{equation}
gives the fraction of information in a meta-analysis associated with effects that are missing any data.
In the Tanner-Smith et al. example, effects that are missing any covariates make up roughly `r round(any_sum %>% pull(wt_pct), 1)`% of the total precision in the data.


The quantity
\begin{equation}
\sum_{i=1}^k \frac{(1 - R_{ij})/\sigma_i^2}{\sum_{i=1}^k 1/\sigma_i^2}
\end{equation}
is the percentage of information associated with effects missing a specific variable. 
If the weighted percentage (4) is greater than the raw percentage in (2) or if (5) is greater than (3), that would indicate that a missingness problem may be more acute because data is missing from larger studies.

Raw percentages and precision-weighted percentages are presented in Table \@ref(tab:pcts).
We would discourage interpreting the size of the differences between the raw and weighted percentages, however comparing those columns can identify variables missing from larger studies, which typically receive more weight in a meta-analysis. 
For example, the raw percentage column and Figure \@ref(fig:figs2) would suggest missingness in the hours per week that Group 1 spent  in treatment (24% missing) may be much less acute than missingness in the hours per week Group 2 spent in treatment (over 46% missing).
But the weighted percentage indicates that the effects for which Group 1's hours per week variable is missing make up nearly 37% of the total precision of effect estimates. 
Hence, excluding those effects in a complete-case or available-case analysis would reduce how accurately the relationship between Group 1's treatment intensity and the intervention's impact can be assessed.
This reduction in accuracy would likely be greater than what is indicated by the raw percentages.


```{r pcts, echo=FALSE, message = F, fig.pos = 'p'}
tab1 <- mis_ma_var_summary(data, se_col = "se_g", truncate = TRUE) %>%
  arrange(desc(wtpct_miss)) %>%
  mutate_if(is.double, round, digits = 1) %>%
  select(Variable, `# Missing` = n_miss, `% Missing` = pct_miss, `Wt. % Missing` = wtpct_miss) %>%
  mutate(Variable = map_chr(Variable, raw_to_named)) 
# library(flextable)
# t1 = flextable(tab1, col_keys = c("Variable", "\\# Missing", "\\% Missing", "Weighted \\% Missing"))
# t1 = set_caption(t1, caption = "\\label{tab:pcts} *This table displays the total number, percentage, and precision-weighted percentage of effect sizes that are missing a given variable*")
# t1
knitr::kable(tab1, format = "latex", caption = "\\label{tab:pcts} \\textit{This table displays the total number, percentage, and precision-weighted percentage of effect sizes that are missing a given variable.}")
```







# Visual Displays of Missingness

Visualizations of missingness can help provide context to the numerical summaries in the previous section. 
In addition, they can help analysts uncover key missingness patterns, as well as examine relationships between missingness and observed data.
This section examines missingness in the Tanner-Smith et al. data using a series of plots.

### Aggregation Plots

*Aggregation plots* provide a high-level picture of missingness in a dataset, and are a useful starting point for EMA visualizations.
Figure \@ref(fig:figs1) shows an aggregation plot for the Tanner-Smith et al. data. 
The plot is laid out exactly like the data: The columns correspond to variables in the data, and rows correspond to effect sizes.
Dark areas correspond to cells that are missing values.

```{r, echo = F, message = F, warning = F}
#Visualize whole dataframe at once
visdat<- vis_dat(data_named) +
    theme(
          legend.position = "bottom",
          legend.title = element_text(size = 8),
          legend.text = element_text(size = 7),
          legend.key.size = unit(.4, "cm"),
          axis.text.x = element_text(size = 7, 
                                     angle = 77.5)
    )
  #summary of whether the data is missing or not
vismiss<-vis_miss(data_named) +
  theme(
        legend.text = element_text(size = 7),
        legend.key.size = unit(.5, "cm"),
        axis.text.x = element_text(size = 7, 
                                   angle = 77.5)
  )
  
# Arrange plots in a grid
prow <- plot_grid(
                  visdat,
                  vismiss + labs(y = ""),
                  labels=c('A','B'),
                  nrow=1, 
                  rel_widths = c(1, 1.1)
                )
```

```{r figs1, echo=FALSE, fig.width = 6, fig.height = 6, fig.pos = 'p', fig.cap="\\label{fig:figs1} *This plot indicates the severity of missingness in the adolescent substance abuse intervention data. Each row in the plot corresponds to a row in the data, and each column corresponds to a variable collected in the data. Missing cells in the data are indicated by a dark dash in plot. The legend shows the percent of cells in the data that contain missing values. The column labels show the precent of rows missing each variable in the data.*", echo = F, message = F, warning = F}
vismiss
```


Aggregation plots can identify which columns are not missing data, such as the columns corresponding to the effect size estimates, standard errors, or study designs in Figure \@ref(fig:figs1).
They also show which columns or groups of columns contain many missing values.
In particular, Figure \@ref(fig:figs1) appears to show three general kinds of missingness patterns. 
First, studies are missing information on the treatment intensity (hours per week and duration) for Group 1 or Group 2.
Note that occasionally this information is missing for both groups, as with the rows near the top of the plot.
Second, studies are missing information on the demographic makeup (percent of the group that is white, black, Hispanic, or male) for Group 1 and Group 2 simultaneously.
Finally, for a number of rows in the middle of the data, it appears that studies are missing information both on Group 2's treatment intensity and demographics.

Figure \@ref(fig:figs1) also displays some numerical summaries regarding the extent of missingness in the data. 
In the legend, we see that over 11% of all cells are missing values in the data. 
Figure \@ref(fig:figs1) also reports the percent of each column that is missing, which aligns with the raw percentages in Table \@ref(tab:pcts).



### Univariate Explorations

While aggregation plots can provide a good overview, we typically want more detailed information about how many observations are missing a given variable. 
*Variable missing plots* display the overall missingness in each column of a dataset, and can be used as an analog to the numerical summaries in Table \@ref(tab:pcts).
From variable missing plots, it is often easy to identify variables that might be driving any missing data problems, and they can quantify the extent to which a given column has missing values on the scale of raw percentages.

Figure \@ref(fig:figs2) shows a variable missing plot for the Tanner-Smith et al. data. 
Each variable is listed on the $y$-axis, and the line extending along the $x$-axis indicates the fraction of rows for which a variable is missing.
Figure \@ref(fig:figs2) suggests that the hours per week that Group 2 spent in their assigned treatment is missing for almost half of the effects in the data, while the hours per week that Group 1 spent in treatment was missing for far fewer rows---roughly half as many.
Further, the percentage of each group that is black or Hispanic is missing more frequently than is the percentage of each group that is white.
That is, studies reported the breakdown of white/non-white adolescents in their studies more frequently than they reported the percentage of adolescents identifying as a specific non-white race.

```{r figs2, echo=FALSE, fig.width=5.5, fig.height=3.1, fig.pos="p", fig.cap = "\\label{fig:figs2} *This plot summaries missingness in variables, ordered by missingness, in the adolescent substance abuse intervention data. Indicating that there are 10 variables with at least 10% of missing cases. This kind of visualization becomes relevant when deciding which variable to include in the analysis.*"}
#summary of missing variables (percentage)
gg_miss_var(data_named, show_pct=TRUE)+
                                      labs(y="Percentage Missing")+
                                      theme(axis.title.x = element_text(size =10),
                                            axis.text.y = element_text(size=6))
```



### Plots Missingness Patterns

Understanding missingness patterns can be crucial for statistical analysis methods of incomplete data.
Such methods often rely on relationships between variables in the observed data as part of their adjustments for missing data.
For instance, good imputation models typically use variables that are predictive of variable that is missing values.
If variables that are seemingly closely related are often missing together, this can limit the accuracy of such methods.

One useful plot for unpacking missingness patterns is to examine the correlation between missingness in one variable versus missingness in another variable (i.e., the correlation between $1 - R_{is}$ and $1 - R_{it}$ for $s \neq t$).
Figure \@ref(fig:missingness_corr) shows a heatmap of pairwise correlations of missingness between variables. 
Each tile corresponds to a pair of variables, and tiles are shaded according to the correlation of missingness between those variables. 
Figure \@ref(fig:missingness_corr) shows a few clusters of variables that tend to be missing together. 
First, information about Group 2's treatment, including duration and intensity, are frequently missing from the same effects. 
Second, if information on the percentage of minorities is missing for one of the groups (e.g., Group 1), then it is very likely to be missing for the other group (e.g., Group 2).
Finally, missingness in Group 2's treatment, including location, duration, and intensity, is positively correlated with missingness in Group 1's treatment duration (in number of sessions), and is negatively correlated with missingness in Group 1's treatment intensity (in hours per week).

```{r misscor, echo=FALSE, fig.width=6.5, fig.height=5, fig.pos = 'p', fig.cap="\\label{fig:missingness_corr} *This plot shows the pairwise correlation of missingnes for each variable in the data. Each tile refers to a pair of variables and is shaded according to the correlation.*"}
library(viridis)

adt_mc_named <- data_named %>%
  select_if(any_na) %>%
  mutate_all(.funs = function(x) ifelse(is.na(x), 1, 0))

miscor <- cor(adt_mc_named) 

ggcorrplot::ggcorrplot(miscor, type = "lower") +
  geom_tile(height = 2.1, width = 1.1) +
  scale_fill_viridis("Correlation of\nMissingness")

# reshape2::melt(miscor) %>%
# ggplot(.) + 
#   aes(Var1, Var2, fill = value) +
#   geom_tile(height = 1.2, width = 1.3) +
#   scale_fill_viridis() +
#   theme_minimal() +
#   theme(axis.text.x = element_text(size=13, angle=45, vjust=1, hjust=1, 
#                                    margin=margin(-3,0,0,0)),
#         axis.text.y=element_text(size=13),
#         panel.grid.major=element_blank()) +
#   labs(x = "", y = "") 
```


A more fine-grained approach to studying missingness patterns uses an *upset plot*, which is shown in Figure \@ref(fig:figs3) [@conwayUpSetRPackageVisualization2017].
The bottom of Figure \@ref(fig:figs3) presents different variables and indicates how many rows each of those variables is missing from.
The dots along the bottom panel indicate different patterns of missingness, which means that a given set of variables are missing from the same row(s).
The bars in the top panel of Figure \@ref(fig:figs3) show the frequency with which these patterns occur.

The bottom four variables listed in Figure \@ref(fig:figs3) involve the treatment duration and intensity for Group 2.
Four of the top five variables listed involve the racial composition of the studies. 
Judging by the bottom panel in the figure, there are few different patterns worth noting. 
The first pattern, in which much of the information about the treatment condition in Group 2 is missing.
However, that pattern also occurs in conjunction with other patterns. 
For instance, the sixth pattern involves rows that are missing information about Group 2's treatment, as well as the racial composition of the study.

In the top panel, we see how frequently each pattern occurs. 
The first pattern, which largely contains information about Group 2's treatment duration and intensity, occurs for 38 rows in the data.
However, because that pattern is part of other patterns, it  occurs frequently in the data.
Judging from Figure \@ref(fig:figs3), many rows are  missing information about Group 2's treatment, and several of those rows are also missing other variables, including variables that describe the demographics of the study participants.

```{r figs3, echo=FALSE, fig.width=5.5, fig.height=4.25, fig.pos = 'p', fig.cap="\\label{fig:figs3} *This plot details those variables that are missing together. For instance, there are a large number of cases where group 2 level of care, number of sessions, treatment contact (hours per week) and duration of treatment (days) are missing together. This simple exploration provides valuable information for imputation.*"}
gg_miss_upset(data_named, nsets=11, nintersects=NA) 
```


### Relating Missingness to Observed Values 

Explorations of missingness can also examine whether missingness in one variable is related to observed values in another variable. 
This can highlight potential biases in the observed data, and give insight into the mechanism of missingness. 
The *missingness mechanism* is an important consideration for incomplete data analyses. 
@rubinInferenceMissingData1976 classified three different possible types of mechanisms that relate the probability that a value is observed $\mathbf{R}$ to the observed and unobserved data $\mathbf{D}_{obs}$ and $\mathbf{D}_{mis}$.
Data are missing completely at random (MCAR) if the probability that values are observed is independent of all observed and unobserved data $p(\mathbf{R} | \mathbf{D}_{obs}, \mathbf{D}_{mis}) = p(\mathbf{R})$.
Data are said to be missing at random (MAR) if the probability that values are observed only depenends on observed data $p(\mathbf{R} | \mathbf{D}_{obs}, \mathbf{D}_{mis}) = p(\mathbf{R} | \mathbf{D}_{obs})$.
Finally, data are missing not at random (MNAR) if the probability of observing a value is related to unobserved and observed data.

@pigottHandlingMissingData2019 argues that some meta-analytic methods, such as analyses of complete cases, assume that data are MCAR.
Other methods, such as multiple imputation or the EM algorithm, assume that data are MAR.
If missingness in one column of the data is correlated with observed values in another column, that would be an indication that data are not MCAR.
A similar logic underpins the test for MCAR proposed by [@littleTestMissingCompletely1988].
While the visualizations presented in this section can be suggestive of MCAR or MAR mechanisms, they are not conclusive about the mechanism. 

Heatmaps, like that in Figure \@ref(fig:hmg1) can help demonstrate the correlation between missingness in one column and observed values of categorical variables.
Figure \@ref(fig:hmg1) plots the missingness rate for each variable as it relates to Group 1's treatment location.
The figure is grouped into tiles. 
The columns of the figure correspond to the different types of care provided to Group 1, shown along the bottom of the graph: inpatient, outpatient, or continuing care.
The rows of the figure correspond to other variables in the dataset.
Each tile is shaded according to how frequently those variables are missing for each level of care provided.

Figure \@ref(fig:hmg1) shows that missingness in other variables is more common for effects where Group 1 received inpatient or continuing care treatment.
In particular, studies where Group 1 received outpatient treatment were more likely to report racial demographics, information about Group 1's treatment intensity (in hours per week) and duration (in days and number of sessions).
Likewise, studies where Group 1 received outpatient care were more likely to report characteristics of Group 2's treatment type, duration, and intensity.
We should note, however, that the *Inpatient* column should be interpreted with some caution, as only five (5) effects in the raw data involve Group 1 receiving inpatient treatment.
Still, the differences in missingness for effects where Group 1 received outpatient versus continuing care interventions suggest that missingness in several variables is related to the venue of treatment.

```{r, hmg1, echo=FALSE, message = F, warning = F, fig.width=6.35,fig.height=4.5, fig.cap="\\label{fig:hmg1} *This plot shows the rate of missingness for each variable as a function of Group 1's treatment location. Each column is broken down by where Group 1 received treatment (inpatient, outpatient, and continuing care). Each row represents another variable in the data. Tiles are shaded according the the fraction rows in the data for which each variable is missing for a given level of Group 1 treatment location.*", fig.pos = 'p'}
na_pct = function(x){
  return(mean(is.na(x)))
}

g1care = data_named %>%
  mutate(`Group 1 Treatment Location` = factor(`Group 1 Treatment Location`, labels = c("Inpatient", "Outpatient", "Continuing Care"))) %>% 
  group_by(`Group 1 Treatment Location`) %>%
  summarize_all(list(na_pct)) %>%
  pivot_longer(`Effect Size`:`Group 2 Pct Male`, 
               names_to = "Variable", 
               values_to = "pct_miss") %>%
  mutate(Variable = factor(Variable), 
         Variable = fct_relevel(Variable, 
                                "Design", 
                                "Timing of Follow-Up",
                                "Effect Size", 
                                "Standard Error"))
ggplot(g1care) +
  geom_tile(aes(`Group 1 Treatment Location`, Variable, 
                fill = pct_miss)) + 
  scale_fill_viridis("% Missing", 
                     labels = scales::percent) + 
  labs(y = "") +
  theme(panel.background = element_blank())
```


Similar patterns emerge in Figure \@ref(fig:hmg2), which shows that missingness in several variables is also correlated with the venue of Group 2's treatment.
Note that Figure \@ref(fig:hmg2) includes an *NA* column, which indicates that Group 2's treatment location is itself missing.
As with Figure \@ref(fig:hmg1), the *Inpatient* column is difficult to really interpret as it represents only one (1) effect in the raw data. 
However, comparing the *Outpatient* and *Continuing Care* columns reveals that studies where Group 2 received outpatient care were more likely to report other variables, particularly those related to treatment intensity (in hours per week) and racial composition.
In addition, the *NA* column in Figure \@ref(fig:hmg2), which indicates that Group 2's treatment location is missing, also confirms a notable missingness pattern identified in Figure \@ref(fig:figs3). 
The relevant rows in \@ref(fig:hmg2) indicate that aspects about Group 2's treatment, including location, duration, an intensity, are often missing together.


```{r hmg2, echo=FALSE, fig.cap="\\label{fig:hmg2} *This plot shows the rate of missingness for each variable as a function of Group 2's treatment location. Each column is broken down by where Group 2 received treatment (inpatient, outpatient, and continuing care). Each row represents another variable in the data. Tiles are shaded according the the fraction rows in the data for which each variable is missing for a given level of Group 2 treatment location.*", fig.height=4.5, fig.pos='p', fig.width=6.35, message=FALSE, warning=FALSE}
#Level of care group 2
foo = data_named %>%
  mutate(`Group 2 Treatment Location` = factor(`Group 2 Treatment Location`, labels = c("Inpatient", "Outpatient", "Continuing Care"))) %>% 
  group_by(`Group 2 Treatment Location`) %>%
  summarize_all(list(na_pct)) %>%
  pivot_longer(`Effect Size`:`Group 2 Pct Male`, 
               names_to = "Variable", 
               values_to = "pct_miss") %>%
  mutate(Variable = factor(Variable), 
         Variable = fct_relevel(Variable, 
                                "Design", 
                                "Timing of Follow-Up",
                                "Effect Size", 
                                "Standard Error"))
ggplot(foo) +
  geom_tile(aes(`Group 2 Treatment Location`, Variable, 
                fill = pct_miss)) + 
  scale_fill_viridis("% Missing", 
                     labels = scales::percent) + 
  labs(y = "") +
  theme(panel.background = element_blank())
```



Two crucial variables that are in nearly all meta-analyses are the effect size estimates and their standard errors $\sigma_i$ (or variances $\sigma_i^2$). 
If missingness in a covariate is correlated with effect sizes or standard errors, this is likely to impact the analytic results.
One way to explore such relationships are with  *comparative density plots* that present the distribution of effect estimates and standard errors among effects for which a covariate is missing versus when the covariate is observed.
Figure \@ref(fig:esseg1) displays several density plot pairs for different variables.
For each pair of plots we see the distribution of effect estimates (left) and standard errors (right), each colored according to whether a given covariate is missing.

Figure \@ref(fig:esseg1)A, shows the relationship between the missingness in Group 1's treatment intensity (in hours per week) and the distribution of effect estimates and standard errors.
Effects are on the scale of Cohen's $d$.
From Figure \@ref(fig:esseg1)A, we can see that effect estimates for which Group 1's treatment intensity is missing tend to be slightly smaller than the effect estimates for which Group 1's treatment intensity is observed. 
Effect estimates tend to have smaller standard errors when Group 1's treatment intensity is missing than when it is reported.
This is consistent with the weighted percentages reported in Table 1, which found that missingness in Group 1's treatment intensity occurred with studies with greater precision.

Contrast that with Figure \@ref(fig:esseg1)B, which focuses on whether Group 1's treatment duration (in days) is missing or not. 
Figure \@ref(fig:esseg1)B shows that effect estimates for which Group 1's treatment duration is missing tend to be larger and have larger standard errors than effects for which duration of treatment is reported.
Plots A and B suggest that missingness of information about treatment dosage will be related to the size of effects found and how precisely those effects were estimated.


```{r esseg1, echo=FALSE, fig.width=6,fig.height=5, fig.cap="\\label{fig:esseg1} *This figure compares the distribution of effect size estimates and standard errors for when various covariates regarding Group 1 are observed versus missing. Plot (A) compares the distribution effect size estimates and standard erors for when Group 1 treatment intensity (hours per week) is missing versus observed. Plot (B) compares the distributions for when Group 1 treatment duration (in days) is observed versus missing.*", fig.pos='p'}
adt_shadow <- bind_shadow(data)
PlotA<- gg_esse_covariate_miss(adt_shadow,
                       es_col = "es_g",
                       se_col = "se_g",
                       covariate = "g1hrsperweek",
                       adjust = c(1.3, 1.2), # Adjust smoothing for ES and SE densitites
                       label = "Group 1 Hours Per Week", 
                       legend_pos = "top")

PlotB<- gg_esse_covariate_miss(adt_shadow,
                       es_col = "es_g",
                       se_col = "se_g",
                       covariate = "g1txdays",
                       adjust = c(1.3, 1.2), # Adjust smoothing for ES and SE densitites
                       label = "Group 1 Duration of Treatment (Days)", 
                       legend_pos = "top")

plot_grid(PlotA, PlotB, 
          labels=c('A','B'),
          nrow=2)

```

Figure \@ref(fig:esseg2) shows an analogous set of plots, only it compares the effect size estimate and standard error distributions for when Group 2's treatment intensity (in hours per week) and duration (in days) are missing or observed.
Figure \@ref(fig:esseg2)A shows that when Group 2's treatment intensity is observed, effect sizes and standard errors are slightly smaller, though not drastically different than when Group 2's treatment intensity is missing.
As well, Figure \@ref(fig:esseg2)B suggests that effect estimates and standard errors are slightly smaller, though not particularly different, when Group 2's treatment duration is observed compared to when it is missing.
Comparing Figures \@ref(fig:esseg1) and \@ref(fig:esseg2) reveals that missingness in variables pertaining to Group 1's treatment has a stronger relationship with the effect size estimates and standard errors than does missingness in variables pertaining to Group 2's treatment. 
This suggests that omitting effects for which Group 1's treatment duration or intensity are missing would seemingly have a stronger impact on an analysis. 

```{r esseg2, echo = F, message = F, warning = F, fig.width=6,fig.height=5, fig.cap="\\label{fig:esseg2} *This figure compares the distribution of effect size estimates and standard errors for when various covariates regarding Group 2 are observed versus missing. Plot (A) compares the distribution effect size estimates and standard erors for when Group 2 treatment intensity (hours per week) is missing versus observed. Plot (B) compares the distributions for when Group 2 treatment duration (in days) is observed versus missing.*", fig.pos='p'}
PlotC<- gg_esse_covariate_miss(adt_shadow,
                       es_col = "es_g",
                       se_col = "se_g",
                       covariate = "g2hrsperweek",
                       adjust = c(1.3, 1.2), # Adjust smoothing for ES and SE densitites
                       label = "Group 2 Hours Per Week", 
                       legend_pos = "top")
PlotD<- gg_esse_covariate_miss(adt_shadow,
                       es_col = "es_g",
                       se_col = "se_g",
                       covariate = "g2txdays",
                       adjust = c(1.3, 1.2), # Adjust smoothing for ES and SE densitites
                       label = "Group 2 Duration of Treatment (Days)", 
                       legend_pos = "top")

plot_grid(PlotC, PlotD, 
          labels=c('A','B'),
          nrow=2)
```




# Discussion

Missing data is and will continue to be an issue with most meta-analyses that can affect what we can learn about substance abuse interventions from research syntheses. 
While there are various potential approaches to handling missing data in meta-analysis, most of those approaches assume that the missingness mechanism is known to the analyst. 
This is almost never the case in practice, and instead analysts are often left to hypothesize possible mechanisms.
This article argued that an exploratory analysis of missingness might help analysts better understand and form hypotheses about missingness.
It also outlined and demonstrated some tools that can support exploratory analyses into the scale and correlates of missingness in a meta-analytic dataset.
These tools proved to be useful as a first step to understanding why data is missing.  

These tools were applied to data on a large meta-analysis conducted by @tanner-smithAdolescentSubstanceUse2016 on substance abuse interventions for adolescents. 
We found `r round(any_sum %>% pull(raw_pct), 1)`% of the effect sizes were missing at least one of their corresponding covariates.
This was driven by some variables that were missing frequently (e.g., Group 2 hours of treatment per week).
Our analysis also revealed that missingness in some variables may be more severe than was obvious from first glance (e.g., Group 1 hours of treatment per week).
Variables quantifying the intensity and duration of treatment in a study were frequently missing together.
Finally, we identified some variables whose missingness appears to be related to the size and standard errors of effect size estimates (e.g., Group 1 hours of treatment per week and treatment duration in days), which suggests that missingness was not MCAR.

Conducting an EMA as outlined here provides insight into the evidence base in a meta-analysis. In the example, we have scant information about the duration and intensity of Group 2 interventions and thus can make limited inferences about how treatment effectiveness varies as a function of the comparison group’s treatment. Presenting EMA results can highlight both the gaps and the areas where effect size models are best supported by the data. 

How to proceed from an EMA will depend on what is known about the data collection and missingness.
Based on our analysis, we would be cautious of using analysis methods that assume data are MCAR, such as complete-case analysis or shifting units of analysis.
Tanner-Smith et al. used the EM algorithm to estimate their meta-regression models, which assumes data are MAR.
This is consistent with our findings, and it is a common assumption made in analyses of incomplete data.

The analyses presented, while suggestive, do have several limitations. 
First, data curators and analysts who extract data for a meta-analysis can and perhaps should play a larger role in EMA. 
While our post-hoc analysis had limited input from these individuals, they will almost certainly have some insight about what made particular variables difficult to extract from the literature, and why that may have occurred.
Data curators and analysts can also use the information from EMA to consider alternative ways to create variables from the data that is provided.

Second, it will be impossible to distinguish between data that are MAR or MNAR using the methods demonstrated in this article.
This is because MNAR assumes that missingness is related to data that is not actually observed. 
Thus, in order to study or confirm whether data are MNAR would require some knowledge of the unobserved data.
Analogous limitations have been noted in tests for whether data are MAR or MNAR [@molenberghsEveryMissingnessNot2008; @rhoadsProblemsTestsMissingness2012].

The methodology discussed in this tutorial could be used to create different visualizations than were presented in this paper. Our complementary material develops on these results with a vignette that contains further visualizations and executable code implemented in the `R` computing language. Even though the data on substance abuse interventions for adolescents has a particular structure with information at the effect size level for each study, the tools exposed in this tutorial can be easily applied to other dataset structures. 



<!-- ### Missingness Mechanisms -->

<!-- A key assumption that underpins analyses of incomplete data involves why those values are missing, typically referred to as the missingness *mechanism*. -->
<!-- @rubinInferenceMissingData1976 classified three different possible types of mechanisms. -->
<!-- These mechanisms relate the probability that a value is missing to the observed and unobserved data; that is, they relate $\mathbf{R}$ to the observed and unobserved data. -->

<!-- Rubin noted that data could be missing completely at random (MCAR), which means that the probability that a given value is missing is independent of all of the observed or unobserved data. -->
<!-- This can be expressed as $P[R | \text{observed data}, \text{unobserved data}] = P[R]$, and means the probability that a given value is missing is unrelated to anything observed or unobserved. -->

<!-- Values could be missing at random (MAR), which occurs if the probability that a value is missing depends only on the observed data. -->
<!-- This can be expressed as $P[R | \text{observed data}, \text{unobserved data}] = P[R | \text{observed data}]$.  -->
<!-- Note that this differs from MCAR in that missingness might be related to observed values.  -->
<!-- For instance, suppose studies with smaller sample sizes (and hence larger standard errors) are less likely to report the racial composition of their samples.  -->
<!-- Then, assuming the standard errors are observed, this could be consistent with MAR.  -->
<!-- It would violate an assumption of MCAR, because missingness is related to an observed value: the standard error of an effect estimate. -->

<!-- Finally, data are said to be missing not at random (MNAR) if the probability that a value is missing depends on unobserved data in some way. -->
<!-- This differs from MAR in that missingness depends on unobserved, rather than just observed data. -->
<!-- As an example, suppose that studies with larger standard errors and a greater proportion of minorities are less likely to report the racial composition of their samples. -->
<!-- Then missingness of racial categories in the data would depend on an observed value (the standard error), but also the racial composition that could itself be missing. -->

<!-- It is worth noting that various researchers have proposed hypothesis tests of some of these assumptions. -->
<!-- For instance, @littleTestMissingCompletely1988 describes a test for MCAR, while other authors have posited tests whether data are MAR versus MNAR [@bakerClosedformEstimatesMissing1992; @diggleInformativeDropoutLongitudinal1994; @molenberghsAnalysisLongitudinalOrdinal1997; @troxelAnalysisLongitudinalData2002]. -->
<!-- However these tests may not be appropriate for data typically used in a meta-regression.  -->
<!-- While Little's test assumes that all variables are continuous and normally distributed, meta-regressions frequently involve categorical covariates and the standard errors of effect estimates are likely not normally distributed. -->
<!-- Much of the literature on MAR tests compares specific models for dropout in longitudinal studies, which is almost never an issue for the meta-analyst [@molenberghsEveryMissingnessNot2008; @rhoadsProblemsTestsMissingness2012].  -->


<!-- ### Missingness Patterns -->

<!-- In addition to the mechanism, it is often useful to understand which variables are missing together from the same rows. -->
<!-- For instance, some rows in the Tanner-Smith et al. data are missing the hours of therapy per week for one of the groups, while other rows are missing the hours of therapy per week *and* the percentage of study participants who were minorities. -->
<!-- In other words, different rows in the data exhibit different *missingness patterns*. -->
<!-- Missingness patterns can be thought of examining relationships within the matrix $\mathbf{R}$. -->

<!-- Understanding these patterns can give some insight into missingness mechanisms, but it can also help identify variables that might be more or less useful in dealing with issues that arise from missingness  [@vanbuurenFlexibleImputationMissing2018]. -->
<!-- For instance, suppose an analyst decides to deal with missingness by imputing missing values. -->
<!-- Typically, imputations can be improved by using predictive models that leverage other variables in the dataset.  -->
<!-- However, if a variable to be imputed is frequently missing alongside many other variables in the data, this can affect the accuracy of the imputation model. -->


<!-- ### Missing Data Analysis Methods -->

<!-- There has been a large amount of research into methods for analyzing incomplete data [see @grahamMissingData2012; @littleStatisticalAnalysisMissing2002; @vanbuurenFlexibleImputationMissing2018].  -->
<!-- @pigottHandlingMissingData2019 provides a comprehensive overview of methods for handling missing data in a meta-analysis. -->
<!-- A common approach in meta-analysis is to conduct a complete-case analysis that excludes effects that are missing any variables [@tiptonCurrentPracticesMetaregression2019]. -->
<!-- Meta-analysts also make regular use of *available-case* analyses, which attempts to use all observed data, even rows that may be missing variables.  -->
<!-- Typically, this will involve running regression models that involve one or two covariates at a time, and is sometimes referred to as "shifting units of analysis" [@cooperSynthesizingResearchGuide1998]. -->
<!-- As an example, one might regress the intervention effects on the intervention type in one model, and then on intervention duration in a second model using Tanner-Smith's et al. data. -->
<!-- A related approach is the EM algorithm, which makes use of all the observed data when estimating parameters in a meta-regression using an iterative procedure to obtain maximum likelihood estimates. -->
<!-- Finally, imputing missing values has become increasingly common for statistical analyses of incomplete data in many fields.  -->
<!-- The standard approach is to use a method call multiple imputation, where missing fields are filled in with several values that the missing field might have contained had it not been missing. -->
<!-- This creates several "complete" datasets, each of which are analyzed and the results of those analyses are then pooled [@littleStatisticalAnalysisMissing2002; @rubinMultipleImputationNonresponse1987]. -->

<!-- Methods for analyzing incomplete data rely on assumptions about the missingness mechanism. -->
<!-- Complete-case analyses may be appropriate assuming MCAR, but not necessarily if data are MAR [@littleStatisticalAnalysisMissing2002; @pigottReviewMethodsMissing2001]. -->
<!-- More sophisticated approaches, such as multiple imputation or the EM algorithm, are typically implemented in software in a way that assumes data are MAR but not MNAR [@grahamMissingDataAnalysis2009; @schaferMissingDataOur2002; @vanbuurenFlexibleImputationMissing2018].  -->
<!-- When data are MNAR, the mechanism that produces missingness will typically need to be explicitly modeled in any analysis. -->


<!-- # Exploratory Analyses -->

<!-- The tools discussed in the remainder of this article facilitate exploratory analyses of missingness in a meta-analytic dataset. -->
<!-- Exploratory missingness analyses (EMA) combine numerical and visual summaries in order to better understand the extent and sources of missingness in a dataset [@bujaInteractiveHighdimensionalData1996; @chengVisuallyExploringMissing2015; @tierneyExpandingTidyData2018]. -->
<!-- EMA differ from traditional exploratory data analyses (EDA) because they focus on missingness indicators in $\mathbf{R}$, as well as the relationship between those indicators and the observed data in $\mathbf{D}$. -->
<!-- Many software tools, including most graphics software used to conduct a standard EDA actually delete observations with missing values, which would eliminate  information about missingness [@tierneyVisdatVisualisingWhole2017]. -->

<!-- The point of conducting an EMA is to better understand the pattern and potential impact of the missing data in a meta-analysis, which can aid researchers to make appropriate choices about an analysis strategy. Researchers can explore whether assumptions about the missingness mechanism are defensible and can also highlight areas where evidence is sparse. For example, meta-analysts may hypothesize that average age of the study sample may relate to the effectiveness of an intervention but find that studies report average age in various ways. Looking closely at the data collected in a meta-analysis affords opportunities to create moderators based on information reported more frequently across studies [[@pigottMethodologicalGuidancePaper2020]. EMAs can also highlight gaps in the evidence base by showing what information (e.g., on treatment frequency or setting) is missing from a systematic review. -->

<!-- While the following sections present an example of an EMA, it is worth noting two aspects about EMA to better contextualize this process. -->
<!-- First, it will often be difficult to draw very strong inferences about missingness mechanisms based on exploratory analyses. -->
<!-- Even proposed tests for missingness mechanisms can have misleading results [@molenberghsEveryMissingnessNot2008; @rhoadsProblemsTestsMissingness2012; @seamanWhatMeantMissing2013]. -->
<!-- Instead, EMA can provide support for or help generate theories that explain missingness in ways that are consistent with the mechanisms described above.  -->
<!-- Some of these theories may require consultation with data curators and other individuals who extracted information from the studies reviewed. -->

<!-- Second, there is no single visualization or set of metrics guaranteed to provide a complete picture of missingness for all datasets.  -->
<!-- A plot that is tremendously useful for one dataset may be of less interest for others.  -->
<!-- Any EMA must rely on knowledge of how data were collected and extracted, and can help leverage that knowledge to examine and propose theories about missingness. -->

<!-- In the following sections, we present and discuss an example EMA of Tanner-Smith's et al. data on substance abuse interventions for adolescents. -->
<!-- To simplify presentation, we focus on $p = 20$ variables relevant to the analyses conducted by Tanner-Smith et al. -->
<!-- This example serves to highlight some potential techniques and tools, but it is not exhaustive, and so as part of the supplementary material to this tutorial, we have included a vignette that presents and describes alternative visualizations and numerical summaries of missingness. -->
<!-- Both the demonstration presented in this article and the supplementary vignette are implemented in the `R` software language and draw heavily on the `visdat` and `naniar` libraries with some custom extensions developed specifically for meta-analysis [@tierneyExpandingTidyData2018; @tierneyVisdatVisualisingWhole2017]. -->
<!-- Executable code is included with the supplementary materials. -->


<!-- # Aggregation Plots -->

<!-- *Aggregation plots* can be a useful starting point when exploring missingness in a meta-analytic dataset. -->
<!-- They visualize the entire dataset as a heatmap that indicates which values are missing from which rows. -->
<!-- Figure \@ref(fig:figs1) shows an aggregation plot for the Tanner-Smith et al. data.  -->
<!-- The plot is laid out exactly like the data: The columns correspond to variables in the data, and rows correspond to effect sizes. -->
<!-- Dark areas correspond to cells that are missing values. -->

<!-- ```{r, figs1, echo=FALSE, fig.width = 6, fig.height = 6, fig.cap="\\label{fig:figs1} *This plot indicates the severity of missingness in the adolescent substance abuse intervention data. Each row in the plot corresponds to a row in the data, and each column corresponds to a variable collected in the data. Missing cells in the data are indicated by a dark dash in plot. The legend shows the percent of cells in the data that contain missing values. The column labels show the precent of rows missing each variable in the data.*", fig.pos = 'h', echo = F, message = F, warning = F} -->
<!-- #Visualize whole dataframe at once -->
<!-- visdat<- vis_dat(data_named) + -->
<!--     theme( -->
<!--           legend.position = "bottom", -->
<!--           legend.title = element_text(size = 8), -->
<!--           legend.text = element_text(size = 7), -->
<!--           legend.key.size = unit(.4, "cm"), -->
<!--           axis.text.x = element_text(size = 7,  -->
<!--                                      angle = 77.5) -->
<!--     ) -->
<!--   #summary of whether the data is missing or not -->
<!-- vismiss<-vis_miss(data_named) + -->
<!--   theme( -->
<!--         legend.text = element_text(size = 7), -->
<!--         legend.key.size = unit(.5, "cm"), -->
<!--         axis.text.x = element_text(size = 7,  -->
<!--                                    angle = 77.5) -->
<!--   ) -->

<!-- # Arrange plots in a grid -->
<!-- prow <- plot_grid( -->
<!--                   visdat, -->
<!--                   vismiss + labs(y = ""), -->
<!--                   labels=c('A','B'), -->
<!--                   nrow=1,  -->
<!--                   rel_widths = c(1, 1.1) -->
<!--                 ) -->
<!-- # prow -->
<!-- vismiss -->
<!-- # Create grid plot -->
<!-- # out_1 <- plot_grid(prow, ncol=1, rel_heights=c(1, 0.03))  -->
<!-- # gg_summary_covariate_miss(data_named) -->
<!-- ``` -->

<!-- Aggregation plots provide a high-level picture of missingness in a dataset.  -->
<!-- They can indicate which columns are complete, such as the columns corresponding to the effect size estimates, standard errors, or study designs. -->
<!-- They also show which columns or groups of columns contain many missing values. -->
<!-- In particular, Figure \@ref(fig:figs1) appears to show three general kinds of missingness patterns.  -->
<!-- First, studies are missing information on the treatment intensity (hours per week and duration) for Group 1 or Group 2. -->
<!-- Note that occasionally this information is missing for both groups, as with the rows near the top of the plot. -->
<!-- Second, studies are missing information on the demographic makeup (percent of the group that is white, black, Hispanic, or male) for Group 1 and Group 2 simultaneously. -->
<!-- Finally, for a number of rows in the middle of the data, it appears that studies are missing information both on Group 2's treatment intensity and demographics. -->

<!-- ```{r, echo = F, message = F, warning = F} -->
<!-- any_sum = any_na_tab %>%  -->
<!--   summarize(raw_pct = mean(any_na) * 100,  -->
<!--             wt_pct = sum(any_na/se^2)/sum(1/se^2) * 100) -->
<!-- ``` -->


<!-- Figure \@ref(fig:figs1) also displays some numerical summaries regarding the extent of missingness in the data.  -->
<!-- In the legend, we see that over 11% of all cells are missing values in the table.  -->
<!-- Figure \@ref(fig:figs1) also reports the percent of each column that is missing. -->
<!-- Overall, `r round(any_sum %>% pull(raw_pct), 1)`% of rows are missing at least one value, and effects that are missing any covariate make up roughly `r round(any_sum %>% pull(wt_pct), 1)`% of the total precision in the data. -->
<!-- Thus, a complete-case analysis of all variables would require dropping over `r floor(100 - any_sum %>% pull(raw_pct))`% of the rows in the data.  -->




<!-- Previously, we argued that precision-weighted percentages may be more informative in describing the extent of missingness in a meta-analysis. -->
<!-- Raw percentages and precision-weighted percentages are presented in Table \@ref(tab:pcts). -->
<!-- We would discourage interpreting the size of the differences between the raw and weighted percentages, however comparing those columns can identify variables missing from larger studies, which typically receive more weight in a meta-analysis.  -->
<!-- For example, the raw percentage column and Figure \@ref(fig:figs2) would suggest missingness in the hours per week that Group 1 spent  in treatment (24% missing) may be much less acute than missingness in the hours per week Group 2 spent in treatment (over 46% missing). -->
<!-- But the weighted percentage indicates that the effects for which Group 1's hours per week variable is missing make up nearly 37% of the total precision of effect estimates.  -->
<!-- Hence, excluding those effects in a complete-case or available-case analysis would reduce how accurately the relationship between Group 1's treatment intensity and the intervention's impact can be assessed. -->
<!-- This reduction in accuracy would likely be greater than what is indicated by the raw percentages. -->



<!-- ```{r pcts, echo=FALSE, message = F, fig.pos = 'h'} -->
<!-- tab1 <- mis_ma_var_summary(data, se_col = "se_g", truncate = TRUE) %>% -->
<!--   arrange(desc(wtpct_miss)) %>% -->
<!--   mutate_if(is.double, round, digits = 1) %>% -->
<!--   select(Variable, `# Missing` = n_miss, `% Missing` = pct_miss, `Wt. % Missing` = wtpct_miss) %>% -->
<!--   mutate(Variable = map_chr(Variable, raw_to_named))  -->
<!-- # library(flextable) -->
<!-- # t1 = flextable(tab1, col_keys = c("Variable", "\\# Missing", "\\% Missing", "Weighted \\% Missing")) -->
<!-- # t1 = set_caption(t1, caption = "\\label{tab:pcts} *This table displays the total number, percentage, and precision-weighted percentage of effect sizes that are missing a given variable*") -->
<!-- # t1 -->
<!-- knitr::kable(tab1, format = "pandoc", caption = "\\label{tab:pcts} \\textit{This table displays the total number, percentage, and precision-weighted percentage of effect sizes that are missing a given variable.}") -->
<!-- ``` -->





\newpage

# References

\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}
\setlength{\parskip}{8pt}
\noindent