---
title: "Exploratory Analyses for Missing Data in Meta-Analyses"
csl: ./addons/alcohol-and-alcoholism.csl
output:
  bookdown::pdf_document2: 
    fig_caption: yes
    includes:
      in_header: ./addons/style.sty
    toc: false
    number_sections: no
  bookdown::word_document2: default
bibliography: ./addons/references.json
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, message=FALSE, echo=FALSE}
library(naniar)
library(ggplot2)
library(visdat)
library(tidyverse)
library(tidyselect)
library(gridExtra)
library(grid)
library(cowplot)
adt_data <- readRDS("../data/adt_data.RDS") 
```


## Introduction


Systematic reviews of substance abuse research hold great promise for examining what makes different substance abuse interventions effective [@tanner-smithComparativeEffectivenessOutpatient2013; @tanner-smithMetaanalysisBriefAlcohol2016]. 
Methodological tools such as meta-regression can formally test relationships between how effective an intervention is and how or on whom it is implemented [@cooperHandbookResearchSynthesis2019; @hedgesStatisticalMethodsMetaanalysis1985; @tiptonHistoryMetaregressionTechnical2019].
However, such tools must contend with the real-world difficulties of modern research syntheses, including the fact that it is often impossible to extract all relevant information from the literature to conduct such analyses.

The fact that not every study reports the information required to run a meta-regression means that many meta-analyses face missing data problems [@pigottHandlingMissingData2019].
Issues with missing data are not new. 
There is a vast literature on methods for handling missing data in primary studies, as well as work on related issues in meta-analysis [@grahamMissingDataAnalysis2009; @littleStatisticalAnalysisMissing2002; @pigottHandlingMissingData2019; @pigottMissingPredictorsModels2001; @rubinInferenceMissingData1976; @schaferMissingDataOur2002; @vanbuurenFlexibleImputationMissing2018].
This literature highlights the ways that missingness can bias an analysis, examines conditions under which these biases can be corrected, and proposes various statistical procedures to adjust for bias.

Diagnosing missing data issues remains an important aspect of any statistical analysis of incomplete data (i.e., data with missing values).
Understanding what and how much data is missing, and how problematic that is, is crucial in determining how to proceed in a meta-analysis and how to to contextualize the results.
A key assumption of analyses involving missing data is that the analyst has some idea about why data is missing.
While much of the literature has focused on the implications of that assumption, considerably less attention is paid to approaches to examining it in a dataset [@tierneyExpandingTidyData2018].

Recent research has suggested analysts can better understand missingness in their data through exploratory analyses, including visual and numerical summaries akin to classical exploratory data analyses [@bujaInteractiveHighdimensionalData1996; @chengVisuallyExploringMissing2015].
These explorations, which occur before conducting the formal meta-analysis, can shed greater light on key issues relevant to missingness.
Tools for doing so are only now emerging, but these tools have yet to gain broader traction in quantitative disciplines [@tierneyExpandingTidyData2018; @tierneyVisdatVisualisingWhole2017]. 
Nor has this approach seemingly made its way into modern meta-analyses, where missing data is a common problem. 

This tutorial discusses tools for exploring and diagnosing missing data problems in meta-analysis. 
The following section clarifies the types of missing data for which these tools are appropriate.
We then describe principles of missing data that can guide exploratory analyses. 
Finally, we demonstrate some of these tools on data from a meta-analysis on substance abuse interventions for adolescents.
Furthermore, our supplementary material expands on these results with a vignette that contains additional visualizations and executable code.



## Missing Data and Meta-Analysis

Because a meta-analysis involves a series of primary studies, "missing data" in meta-analysis can be seen as a broad term that could refer to several different scenarios.
For instance, data could be missing on individual participants within studies, including their outcomes in the study or other characteristics (e.g., their age, race, prior substance use) [e.g., @higginsImputationMethodsMissing2008].
"Missing data" could also refer to information that couldnâ€™t be extracted from a completed study by a meta-analyst [@pigottMissingPredictorsModels2001]. 
This might occur if a study fails to report enough detail for analysts to back out effect estimates, standard errors, or study-level characteristics.
Finally, entire studies or effects may be missing from a meta-analytic dataset. 
This might occur if effects (or entire studies) are not reported or published [@rosenthalFileDrawerProblem1979]. 
There is empirical evidence that statistically significant results are more likely to be published and hence wind up in a meta-analysis, which can induce *publication bias*, a well-known problem in the field [@hedgesEstimationEffectSize1984; @rothsteinPublicationBiasMetaanalysis2005].
The studies or effects that are not reported, and thus are not included in a meta-analysis, can be considered missing data.

Precisely how to examine, diagnose, and adjust for missing data will be different depending on what scenario we mean when we say "missing data."
For instance, meta-analysts have used *funnel plots* to examine if their systematic review is missing studies or effects due to publication bias [@eggerBiasMetaanalysisDetected1997; @lightSummingScienceReviewing1984].
Our focus will be on the second scenario, where information cannot be extracted from some studies. 
This is a common problem in meta-analysis and one that can limit the accuracy of any statistical inferences [@pigottHandlingMissingData2019; @tiptonCurrentPracticesMetaregression2019].

Assume we have data on $k$ effect estimates and $p$ variables (including the estimate itself).
This can be summarized and stored in a $k \times p$ table where rows correspond to effect estimates and columns correspond to variables concerning those estimates. 
One column would contain the effect estimates themselves, and another would contain the standard error or estimation error variance of those estimates.
The remaining $p-2$ columns could contain effect- or study-level covariates, including summary demographics (e.g., the percent of a study's sample that were minorities), treatment type (e.g., behavioral therapy versus pharmacological interventions), or dosage/duration of an intervention.
Some of the cells in this table may be missing values, and the analyses presented in this article provide ways to summarize and examine these patterns of missingness.



## Data

A prime example of this type of missingness can be seen in data from @tanner-smithAdolescentSubstanceUse2016, who examined the effects of substance abuse interventions for adolescents on subsequent substance use. 
These data were extracted from 61 randomized trials and quasi-experiments, and include $k = 95$ different effect size estimates.  
These estimates involve contrasts between a given treatment condition and a control condition within a study, or between two different treatment conditions in the same study. 
These data will be used to illustrate key concepts of missingness and some useful tools to exploring missingness in this tutorial.

Tanner-Smith et al. found a range of intervention types and venues that have been studied on individuals who use different substances and who differ in a variety of ways. 
Some interventions in their data focus on cognitive behavioral therapy (CBT), family therapy, or pharmacological therapy. 
Some interventions are in-patient, and others are out-patient. 
Individuals in studies might present using marijuana, which is most common among adolescents, or alcohol or opioids, and they may come from wealthy families or poor families. 
Finally, some effects reported in studies contrasted a given intervention with some control condition, while others contrasted two alternative interventions or implementations.

To explore relevant relationships, Tanner-Smith et al. extracted a considerable amount of information from the studies they found. 
Their raw data included some $p = 46$ variables per study.
In addition to estimated effects and their standard errors, they documented the types of interventions being contrasted, as well as their intensity and context.
This included where interventions occurred, and how much time subjects spent in the intervention. 
For instance, if a study contrasted two interventions that involved behavioral therapy, Tanner-Smith et al. documented how many hours per week subjects in each intervention (referred to in this article as *groups*) spent in therapy.
They also documented the demographics of subjects in the studies, such as the percentage of subjects who were minorities, as well as the substances that subjects reported using.

Tanner-Smith et al. then fit a series of meta-regression models to their data in order to examine how treatment effects varied according to the type of therapies and individuals studied. 
They found that assertive continuing care (ACC), behavioral therapy, CBT, motivational enhancement therapy (MET), and family therapy tended to be more effective than generic "practice as usual" interventions that often involved referrals to community services.
However, they did not find strong relationships between the characteristics of adolescents in the studies and the effectiveness of interventions (net of intervention type).

A complicating factor in conducting these analyses was that some of the data were missing. 
Not every study reported the requisite information for extracting covariates for every effect size.
For instance, not all studies reported how many hours per week subjects spend in therapy or the racial or socioeconomic makeup of their subject pool.
As a result, not all effect estimates had information about the types of individuals in the study or the intensity of the interventions.
It was often the case that one or two of the fields in their data table were missing for any given effect estimate.
Thus, when it came time to run meta-regressions, Tanner et al. were faced with a decision about how to address effects for which they had missing covariates.



## Principles of Missing Data

Tanner-Smith et al. ultimately opted for a sophisticated statistical procedure called the expectation-maximization (EM) algorithm to estimate their models, which has been an important tool for analyzing data with missing values.
However, that was not their only option.
A common approach in meta-analysis is a *complete-case* analysis that excludes effects for which any of the relevant covariates in the meta-regression model are missing.

An alternative to complete-case analysis that has gained broad use in various fields is to impute (i.e., fill in) missing values.
@pigottHandlingMissingData2019 discusses the use of single-value imputations in meta-analysis. 
A more common approach to missingness in primary studies is to use multiple imputations for a missing value, which can better reflect the uncertainty introduced by filling in unknown values.
Often imputations are based on predictive models that can better inform what values we might have observed had a given field not been missing.
These predictive models typically leverage information from other variables in the data.

Analyses involving incomplete data will be impacted by which variables are missing in a dataset and how frequently they are missing, as well as relationships between variables.
In this section we provide an overview of principles of missing data that apply to meta-analysis, and list some potential statistical approaches to handling missing data.


### Notation

As noted above, we can describe the datasets commonly used in meta-analysis as tables with $k$ rows and $p$ columns. 
Each row corresponds to an effect size, and each column corresponds to some variable related to that effect.
These are the types of tables used in most standard meta-analysis software, including Comprehensive Meta-Analysis, the `metafor` library, or OpenMetaAnalyst [@borensteinComprehensiveMetaAnalysisVersion2012; @trikalinosOpenMetaAnalystPowerfulOpensource2012; @viechtbauerConductingMetaanalysesMetafor2010].
The structure of these tables is shown in the matrix below. 
In the matrix, $T_i$ denote the effect size estimates and $\sigma_i$ are their standard errors. 
The $X_{ij}$ refer to additional variables collected that pertain to a given effect size and that might be used in an analysis.

\[
\left[
\begin{array}{ccccc}
T_1 & \sigma_1 & X_{11} & ... & X_{1,p-2}\\
T_2 & \sigma_2 & X_{21} & ... & \textbf{NA}\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
T_k & \sigma_k & \textbf{NA} & ... & X_{k,p-2}\\
\end{array}
\right]
\]

Missing values in the matrix are denoted as **NA**. 
Most missing data literature augments the traditional table above with a table $\mathbf{R}$ of response indicators $R_{ij}$.
These indicators take a value of $R_{ij} = 1$ if entry $i, j$ in the table is observed, and $R_{ij} = 0$ if it is missing.
For instance, $R_{21} = 1$ because the first element of row 2 ($T_2$) is observed, but $R_{2p} = 0$ because the last element of row 2 is missing (**NA**).

In the matrix above, there are both *observed* and *unobserved* data.
The observed data comprises all of the entries in the table above for which $R_{ij} = 1$.
For instance, the observed data would include the effect estimates $T_i$ and standard errors $\sigma_i$.
The unobserved data comprises all of the entries for which $R_{ij} = 0$, including $X_{2, p-2}$ and $X_{k, 1}$.
Note that the entire matrix above, and hence the incomplete data on which we conduct an analysis, is simply the union of the observed and unobserved data.

It is often of interest how much data is missing.
This could refer to several different quantitites.
For instance, we could be interested in the total amount of cells with missing values:
\[
\sum_{i=1}^k \sum_{j = 1}^p \frac{1 - R_{ij}}{kp}
\]
We might also be interested in how many observations are missing a given variable (i.e., how much of each column is missing):
\[
\sum_{i=1}^k \frac{1 - R_{ij}}{k}
\]

While such percentages are somewhat intuitive and can be used in exploratory analyses of missingness, they are not the only numerical summary of missingness.
In a meta-analysis, parameters are often estimated by weighting effect size estimates in a way that those estimates that are most precisely estimated (i.e., that have the smallest standard errors) receive the most weight [@borensteinIntroductionMetaanalysis2009; @cooperHandbookResearchSynthesis2019].
The precision with which we estimate important quantities in a meta-analysis, including meta-regression coefficients, will therefore depend on the precision of the studies included in an analysis.
That is, we will have better estimates of a meta-regression model if the precision of each effect $w_i = 1/\sigma_i^2$ is large [@hedgesStatisticalMethodsMetaanalysis1985].
Missing a variable for an effect estimate with a large standard error (and thus low precision $w_i$) can potentially be less detrimental than missing the same variable for an effect estimate with a small standard error (i.e., a large $w_i$).
When standard errors of effect sizes are fully observed, an alternative way to quantify the extent of missingness is with a precision-weighted percentage:
\[
\sum_{i=1}^k \frac{w_i (1 - R_{ij})}{\sum_{i=1}^k w_i}
\]
This describes the percentage of the total precision of effects for which a covariate is missing. 
If this is greater than the raw percentage, that would indicate that the missingness problem may be more acute because larger studies might be missing important covariates.


### Missingness Mechanisms

A key assumption that underpins analyses of a dataset with missing values involves why those values are missing, typically referred to as the missingness *mechanism*.
@rubinInferenceMissingData1976 classified three different possible types of mechanisms.
Rubin noted that data could be missing completely at random (MCAR), which means that the probability that a given value is missing is independent of all of the observed or unobserved data.
This can be expressed as $P[R | \text{observed data}, \text{unobserved data}] = P[R]$, and means the probability that a given value is missing is unrelated to anything observed or unobserved.

Values could be missing at random (MAR), which occurs if the probability that a value is missing depends only on the observed data.
This can be expressed as $P[R | \text{observed data}, \text{unobserved data}] = P[R | | \text{observed data}]$. 
Note that this differs from MCAR in that missingness might be related to observed values. 
For instance, suppose studies with larger standard errors are less likely to report the racial composition of their samples. 
Then, assuming the standard errors are observed, this might constitute MAR. 
It would not constitute MCAR, because missingness is related to an observed value, the standard error of an effect estimate.

Finally, data are said to be missing not at random (MNAR) if the probability that a value is missing depends on the unobserved data in some way.
This differs from MAR in that missingness depends on unobserved data.
As an example, suppose that studies with larger standard errors and a greater proportion of minorities are less likely to report the racial composition of their samples.
Then missingness of racial categories in the data would depend on an observed value (the standard error), but also the racial composition that could itself be missing.



### Missingness Patterns

In addition to the mechanism, it is often useful to understand which variables are missing together from the same rows.
For instance, some rows in the Tanner-Smith et al. data might be missing the hours of therapy per week for one of the groups, while other row may be missing the hours of therapy per week *and* the percentage of study participants who were minorities.
In other words, different rows may exhibit different *missingness patterns*.
Understanding these patterns can give some insight into missingness mechanisms, but it can also help identify variables that might be more or less useful in dealing with issues that arise from missingness  [@vanbuurenFlexibleImputationMissing2018].
For instance, it will be difficult to build imputation models for a variable if it is frequently missing alongside several other variables in the data.
It would also seem useful to examine how missingness in one variable is related to observed values of other variables. 
If missingness in one column (e.g., therapy hours per week) occurs more frequently with low values of another column (e.g., the effect estimate), that might be cause to re-assess any MCAR assumptions.


## Exploratory Analyses

The tools discussed in the remainder of this article facilitate exploratory analyses of missingness in a meta-analytic dataset.
Exploratory missingness analyses (EMA) are difficult for several reasons.
First, they are not always wholly conclusive. 
It will often be difficult to draw ironclad inferences about missingness mechanisms based on exploratory analyses.
Even proposed tests for missingness mechanisms can have misleading results [@molenberghsEveryMissingnessNot2008; @rhoadsProblemsTestsMissingness2012; @seamanWhatMeantMissing2013].
Instead, EMA can provide support for or help generate theories that explain missingness in ways that are consistent with the mechanisms described above. 
Some of these theories may require consultation with data curators and other individuals who extracted information from the studies reviewed.

Second, there is no single visualization or set of metrics guaranteed to provide a complete picture of missingness for all datasets. 
A plot that is tremendously useful for one dataset may be of less interest in others. 

Third, EMA differs from traditional exploratory data analyses because the focus on the unobserved data.
Many software tools, including most graphics software actually deletes observations with missing values, which would eliminate the information EMA seek to understand [@tierneyVisdatVisualisingWhole2017].
Thus, a new and emerging suite of tools that differ from traditional exploratory data analyses are required [@tierneyExpandingTidyData2018].
Moreover, as with the case with much general-use statistical software, adaptations of these tools may be necessary to tailor EMA for meta-analytic datasets.

In the following sections, we show and discuss different types of visualizations and numerical summaries relevant to EMA. 
These are rooted in an approach to understand the scope and correlates of missingness problems in a dataset described in the previous section.
However, they are not exhaustive, and so as part of the supplementary material to this tutorial, we have included a vignette that presents and describes alternative visualization and numerical summaries of missingness.
Both the demonstration presented in this article and the supplementary vignette are implemented in the `R` software language and draw heavily on the `visdat` and `naniar` libraries with some custom extensions developed specifically for meta-analysis [@tierneyExpandingTidyData2018; @tierneyVisdatVisualisingWhole2017].



## Aggregation Plots

Aggregation plots can be a useful starting point when exploring missingness in a meta-analytic dataset.
They visualize the entire dataset as a "heatmap" that indicates which values are missing from which rows.
Two examples of aggregation plots are given in Figure \@ref(fig:figs1) below. These plots are laid out exactly like the data: the columns correspond to variables in the data, and rows correspond to effect sizes.
Figure \@ref(fig:figs1)A colors each column according to the type of variable (e.g., numeric, categorical, etc.) they represent, and gray spots indicate that a value in a given row and column is missing.
Figure \@ref(fig:figs1)B does not specify the type of variables in the data, but instead shows the total number of cells that contain missing values. 
That is, out of all of the $k \times p$ cells in the data, 6.2% are missing values.

Aggregation plots provide a high-level picture of missingness in a dataset. 
They can indicate which columns are complete, such as the columns corresponding to the effect size estimates and standard errors, as well as which columns or groups of columns present plenty of missingness.
In particularly, Figure \@ref(fig:figs1) illustrates that there are groups of variables regarding one of the treatment arms (group 2) in studies that are missing fairly frequently.

Complementing these plots, there are numerical summaries that reveal the number of studies or effect sizes, that contain missing covariates and the percentage of potential data lost, when using methods such as complete-case analysis for addressing missing covariates in a meta-regression analysis. Specifically, 74% of the effect sizes showed missingness in at least one of their corresponding covariates. 



```{r figs1, echo=FALSE,fig.width=6,fig.height=3, fig.cap="\\label{fig:figs1} *These plots indicate the severity of missingness in the adolescent substance abuse intervention data. Each row in the plot corresponds to a row in the data, and each column corresponds to a variable collected in the data. Missing cells in the data are indicated by a gray dash in plot (A) and a black dash in plot (b). Plot (A) additionally colors columns according to the type of variables they store. Plot (B) indicates that 6.2% of the total dataset (i.e., 6.2% of all cells in the table) are missing values.*", fig.pos='h'}
source("../code/wrappers.R")
gg_summary_covariate_miss(adt_data)
```


## Univariate Explorations

While aggregation plots can provide a noble overview, typically we want more detailed information about how many observations are missing a given variable. 
Variable missing plots can yield a convenient way to explore this. 
These plots display the overall missingness in each column of a dataset and present the results in order of which column has the most missingness.  
Figure \@ref(fig:figs2) presents two approaches to making these plots. 
Figure \@ref(fig:figs2)A displays the raw count missing values in each column, while Figure \@ref(fig:figs2)B displays the percent of each column missing.
For example, Figure \@ref(fig:figs2) suggests that the hours per week that the contrast group spent in their assigned condition (`g2hrsperweek`) is missing for almost half of the effects in the data. 

```{r figs2, echo=FALSE,fig.width=6,fig.height=3,fig.cap="\\label{fig:figs2} *These plots summary missingness in variables, ordered by missingness, in the adolescent substance abuse intervention data. Plot (B) indicates that there are 10 variables with at least 10% of missing cases. This kind of visualization becomes relevant when deciding which variable to include in the analysis.*", fig.pos='h'}
#summary of missing variables
p1<- gg_miss_var(adt_data) + 
                            labs(y="Missing Cases")+
                            theme(axis.title.x = element_text(size =10),
                                  axis.text.y = element_text(size=6))
                          

#summary of missing variables (percentage)
p2<- gg_miss_var(adt_data, show_pct=TRUE)+
                                          labs(y="Percentage Missing")+
                                          theme(axis.title.x = element_text(size =10),
                                                axis.text.y = element_text(size=6))
                                                
grid.arrange(p1, p2 + 
                    labs(x=""),
                    ncol = 2)
```


From variable missing plots, it is often easy to identify variables that might be driving any missing data problems, and they can quantify the extent to which a given column has missing values on the scale of raw percentages.
Previously, we argued that precision-weighted percentages may be more informative in describing the extent of missingness in a meta-analysis.
A comparison of raw percentages and precision-weighted percentages is given below:
```{r tab2, echo=FALSE,table.cap="\\label{tab:pcts} *.*", fig.pos='h'}
source("../code/wrappers.R")
tab1 <- mis_ma_var_summary(adt_data, se_col = "se_g", truncate = TRUE) %>%
  mutate_if(is.double, round, digits = 1) %>%
  rename(`# Missing` = n_miss, `% Missing` = pct_miss, `Weighted % Missing` = wtpct_miss)
tab1 %>% knitr::kable()
```




## Exploring Patterns of Missingness

When diagnosing potential missing data problems, it also matters which variables are missing together. 
Certain patterns of missingness can be indicative of the missingness mechanism, and patterns can also point to potential issues for analytic methods with incomplete data, such as multiple imputation or the EM algorithm.

One approach to visualizing missingness patterns is with an *upset plot* [@conwayUpSetRPackageVisualization2017].
Upset plots indicate the frequency with which different combinations of variables are missing together. 
Figure \@ref(fig:figs3) exemplifies an upset plot. 
The bottom of Figure \@ref(fig:figs3) presents different variables, how many rows each of those variables is missing from, and then describes various missingness patterns.
For example, the first missingness pattern corresponds to rows where information about the location (`g2loc_NA`), number of sessions (`g2numsessions_NA`), number of days (`g2txdays_NA`), and hours per week (`g2hrsperweek_NA`) that one of the groups in the study (referred to in the data as "group 2" or `g2` in the plot) spent in treatment are all missing.
The top part of Figure \@ref(fig:figs3) describes how frequently those patterns occur in the data.
For instance, the first pattern, in which much of the information about the treatment implementation is missing for one group in a study, occurs for 38 effects.


```{r figs3, echo=FALSE,fig.width=6,fig.height=4, fig.cap="\\label{fig:figs3} *This plot details those variables that are missing together. For instance, there are a large number of cases where group 2 level of care, number of sessions, treatment contact (hours per week) and duration of treatment (days) are missing together. This simple exploration provides valuable information for imputation.*", fig.pos='h'}
gg_miss_upset(adt_data, nsets=11, nintersects=NA)
```


## Relating Missingness to Observed Values 

Explorations of missingness can also examine whether missingness in one variable is related to observed values in another variable. 
This can highlight potential biases in the observed data.
It can also clarify whether data appear to meet the MCAR assumption. 
The idea behind this is that MCAR assumes that the probability that a value is missing is independent of both observed and unobserved values. 
However, if missingness in a column in the data is correlated with values in another column, that would be an indication that data are not MCAR.
A similar logic underpins the test for MCAR proposed by [@littleTestMissingCompletely1988].

Since covariates in a meta-regression are often categorical, visualizations like the heatmap in Figure \@ref(fig:figs4) can be useful.
Figure \@ref(fig:figs4) demonstrates how missingness in various columns is related to the type of care received in one of the study's treatment arms.
The figure is grouped into tiles or cells. 
The columns of the figure correspond to the different types of care provided shown along the bottom of the graph: inpatient, outpatient, and continuing care, and some of those values are themselves missing (NA).
The rows of the figure correspond to other variables in the dataset.
Each cell is shaded according to how frequently those variables are missing for each level of care provided.
For example, the percent of subjects who are black or hispanic (`g2perblack` and `g2perhisp`) are much more frequently missing from effects with inpatient treatments than outpatient or continuing care interventions.

```{r figs4, echo=FALSE,fig.width=6,fig.height=4, fig.cap="\\label{fig:figs4} *This plot highlights the number of missings in each column, broken down by a factor variable, in this case the level of care for group 2. The inpatient category has 100% of missing values in at least 12 different variables, suggesting that this category could impose a problem when fitting a regression model.*", fig.pos='h'}
#Level of care group 2
gg_miss_fct(x=adt_data, fct=g2loc)  + 
                                    labs(x="Group 2 Level of Care")+
                                    theme(axis.text.y = element_text(size=7))
```



Two crucial variables that are in nearly all modern meta-analyses are the effect size estimates and their estimation error variances or standard errors $\sigma_i$. 
If missingness in a covariate is more likely to occur with smaller or larger effect estimates or smaller or larger standard errors, this is likely to impact the analytic results.
Therefore, it will typically be a good idea to explore such relationships.
Because both effect estimates and standard errors are continuous, density plots may be useful tools.

Density plots present the distribution of effect estimates and standard errors among effects for which a covariate is missing versus when the covariate is observed.
Figure \@ref(fig:figs5) displays several density plot pairs for different variables.
For each pair of plots we see the distribution of effect estimates (left) and standard errors (right), each colored according to whether a given covariate is missing.

Figure \@ref(fig:figs5)A, indicates that effects for which information on hours of treatment received per week is missing tend to be a little smaller on average than those for which the hours per week were reported. 
Moreover, the effects that are not missing the hours per week covariate tend to have larger standard errors.
These differences are more pronounced for the covariate indicating the days of treatment received (plot B).
Bot plots A and B strongly suggest that missingness of information about treatment dosage will be related to the size of effects found and how precisely those effects were estimated.


```{r figs5, echo=FALSE,fig.width=6,fig.height=7, fig.cap="\\label{fig:figs5} *Plot (A) shows that the covariance duration of treatment (days) for group 1 is mostly missing for larger effect size values. Further, the effect size has larger standard error, when this covariate is missing. Plot (B) illustrates a case where the effect size tends to be closer to zero when a particular covariate is missing. Specifically, when treatment contact (hours per week) for group 1 is missing, both the effect size and its standard errors tend to be smaller than when the covariate is present.Plot (C) shows that both, the effect size and its standard errors, have a similar distribution either when the covariate treatment contact (hours per week) for group 2 is present or not.*", fig.pos='h'}
adt_shadow <- bind_shadow(adt_data)
source("../code/wrappers.R")
PlotA<- gg_esse_covariate_miss(adt_shadow,
                       es_col = "es_g",
                       se_col = "se_g",
                       covariate = "g1hrsperweek",
                       adjust = c(1.3, 1.2), # Adjust smoothing for ES and SE densitites
                       label = "Group 1 Hrs Per Week")

PlotB<- gg_esse_covariate_miss(adt_shadow,
                       es_col = "es_g",
                       se_col = "se_g",
                       covariate = "g1txdays",
                       adjust = c(1.3, 1.2), # Adjust smoothing for ES and SE densitites
                       label = "Group 1 Duration of Treatment (Days)")

PlotC<- gg_esse_covariate_miss(adt_shadow,
                       es_col = "es_g",
                       se_col = "se_g",
                       covariate = "g2hrsperweek",
                       adjust = c(1.3, 1.2), # Adjust smoothing for ES and SE densitites
                       label = "Group 2 Hrs Per Week")

plot_grid(PlotA, PlotB, PlotC, 
          labels=c('A','B', 'C'),
          nrow=3)

```


## Discussion

This tutorial has described methods for exploring and diagnosing missing data. Diverse approaches were defined and demonstrated on data from a meta-analysis on substance abuse interventions for adolescents. These tools proved to be useful not only for identifying and quantifying how much data is missing but also as a first step to understanding why data is missing.  

Particularly, findings in our demonstration suggest that missingness of information about some relevant covariates in the data will be related to the size of effects found and how precisely those effects were estimated. Further, 74% of the effect sizes presented missingness in at least one of their corresponding covariates. These kinds of patterns point out potential issues with the missing completely at random assumption and thus methods such as complete-case analysis would not be recommended for addressing missing covariates in a meta-regression analysis. Instead, procedures such as Expectation maximization (EM) algorithm, implemented by Tanner-Smith et al. or imputations methods would be more appropriate for this data. 

The methodology discussed in this tutorial could be used to create different visualizations than were presented in this paper. Our complementary material develops on these results with a vignette that contains further visualizations and executable code. Moreover, even though the data on substance abuse interventions for adolescents has a particular structure with information at the effect size level for each study, the tools exposed in this tutorial can be easily applied to other dataset structures. 


\newpage

## References

\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}
\setlength{\parskip}{8pt}
\noindent